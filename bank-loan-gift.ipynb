{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74882820",
   "metadata": {
    "papermill": {
     "duration": 0.004779,
     "end_time": "2025-03-20T08:43:46.022948",
     "exception": false,
     "start_time": "2025-03-20T08:43:46.018169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bedec402",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-20T08:43:46.033030Z",
     "iopub.status.busy": "2025-03-20T08:43:46.032559Z",
     "iopub.status.idle": "2025-03-20T08:43:52.629593Z",
     "shell.execute_reply": "2025-03-20T08:43:52.628441Z"
    },
    "papermill": {
     "duration": 6.604581,
     "end_time": "2025-03-20T08:43:52.631995",
     "exception": false,
     "start_time": "2025-03-20T08:43:46.027414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44823be6",
   "metadata": {
    "papermill": {
     "duration": 0.003704,
     "end_time": "2025-03-20T08:43:52.639919",
     "exception": false,
     "start_time": "2025-03-20T08:43:52.636215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b8cad0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T08:43:52.650389Z",
     "iopub.status.busy": "2025-03-20T08:43:52.649696Z",
     "iopub.status.idle": "2025-03-20T08:43:52.656315Z",
     "shell.execute_reply": "2025-03-20T08:43:52.655349Z"
    },
    "papermill": {
     "duration": 0.013925,
     "end_time": "2025-03-20T08:43:52.658303",
     "exception": false,
     "start_time": "2025-03-20T08:43:52.644378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_data(file_path, drop_cols, target_col):\n",
    "\n",
    "    # Load dataset with only necessary columns\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f'Initial Data Shape: {df.shape}')\n",
    "\n",
    "    # Drop specified columns efficiently\n",
    "    df.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "    # Remove duplicate rows in place\n",
    "    print(f'Duplicate Rows: { df.duplicated().sum()}')\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    print(f'Shape after dropping duplicates: {df.shape}')\n",
    "\n",
    "    # Standardize features \n",
    "    cols_std = [col for col in df.columns if col != target_col]\n",
    "    print(f'Num of features to standardize: {len(cols_std)}')\n",
    "\n",
    "    if cols_std:  \n",
    "        df[cols_std] = StandardScaler().fit_transform(df[cols_std])\n",
    "\n",
    "    # shuffle df\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0da7b98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T08:43:52.667853Z",
     "iopub.status.busy": "2025-03-20T08:43:52.667500Z",
     "iopub.status.idle": "2025-03-20T08:43:52.674097Z",
     "shell.execute_reply": "2025-03-20T08:43:52.672904Z"
    },
    "papermill": {
     "duration": 0.013202,
     "end_time": "2025-03-20T08:43:52.675735",
     "exception": false,
     "start_time": "2025-03-20T08:43:52.662533",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(df, target_col, test_size=0.1, val_size=0.2):\n",
    "    X, y = df.drop(columns=[target_col]), df[target_col]\n",
    "    # split data  train val , test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, \n",
    "                                                        random_state=42, stratify=y)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_size, \n",
    "                                                      random_state=42, stratify=y_train)\n",
    "\n",
    "    print(f\"Train Shape: {X_train.shape}, Validation Shape: {X_val.shape}, Test Shape: {X_test.shape}\")\n",
    "    target_sets = { \"Train\": y_train, \"Validation\": y_val, \"Test\": y_test }\n",
    "\n",
    "\n",
    "    for set_name, target in target_sets.items():\n",
    "        print(f\"\\nTarget Distribution in {set_name} Set:\")\n",
    "        print(target.value_counts(normalize=True))\n",
    "        \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46476e57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T08:43:52.685239Z",
     "iopub.status.busy": "2025-03-20T08:43:52.684815Z",
     "iopub.status.idle": "2025-03-20T08:43:52.691985Z",
     "shell.execute_reply": "2025-03-20T08:43:52.690904Z"
    },
    "papermill": {
     "duration": 0.013806,
     "end_time": "2025-03-20T08:43:52.693705",
     "exception": false,
     "start_time": "2025-03-20T08:43:52.679899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(model, X_true, y_true):\n",
    "    \n",
    "    # predict class and probability \n",
    "    y_pred = model.predict(X_true)\n",
    "    y_pred_proba = model.predict_proba(X_true)\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0  # True Negative Rate\n",
    "\n",
    "    # Store metrics in a dictionary\n",
    "    metrics_dict = {\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1-Score\": f1,\n",
    "        \"Specificity\": specificity}\n",
    "      \n",
    "    print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "    print(\"\\nEvaluation Metrics:\")\n",
    "    for key, value in metrics_dict.items():\n",
    "        if value is not None: print(f\"{key}: {value:.4f}\")\n",
    "    \n",
    "    return metrics_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a3c103",
   "metadata": {
    "papermill": {
     "duration": 0.003779,
     "end_time": "2025-03-20T08:43:52.701815",
     "exception": false,
     "start_time": "2025-03-20T08:43:52.698036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "480b373a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T08:43:52.711025Z",
     "iopub.status.busy": "2025-03-20T08:43:52.710610Z",
     "iopub.status.idle": "2025-03-20T08:43:52.715260Z",
     "shell.execute_reply": "2025-03-20T08:43:52.714213Z"
    },
    "papermill": {
     "duration": 0.01129,
     "end_time": "2025-03-20T08:43:52.717069",
     "exception": false,
     "start_time": "2025-03-20T08:43:52.705779",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = '/kaggle/input/bank-personal-loan-modelling/Bank_Personal_Loan_Modelling.csv'\n",
    "drop_cols = ['ID', 'ZIP Code']\n",
    "target_col = 'Personal Loan'\n",
    "gift_cols_target = ['Income', 'CCAvg', 'CD Account', 'Education', 'Mortgage', 'Family', 'Personal Loan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a82d344",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T08:43:52.726539Z",
     "iopub.status.busy": "2025-03-20T08:43:52.726208Z",
     "iopub.status.idle": "2025-03-20T08:43:52.731513Z",
     "shell.execute_reply": "2025-03-20T08:43:52.730557Z"
    },
    "papermill": {
     "duration": 0.011994,
     "end_time": "2025-03-20T08:43:52.733194",
     "exception": false,
     "start_time": "2025-03-20T08:43:52.721200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"SVM\" : svm.SVC(probability=True), \n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"LightGBM\": LGBMClassifier() }\n",
    "\n",
    "classifiers_gift = {\n",
    "    \"SVM\" : svm.SVC(probability=True), \n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"LightGBM\": LGBMClassifier() }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690e3e9",
   "metadata": {
    "papermill": {
     "duration": 0.003826,
     "end_time": "2025-03-20T08:43:52.741523",
     "exception": false,
     "start_time": "2025-03-20T08:43:52.737697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b189bc6b",
   "metadata": {
    "papermill": {
     "duration": 0.0037,
     "end_time": "2025-03-20T08:43:52.749395",
     "exception": false,
     "start_time": "2025-03-20T08:43:52.745695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe437dcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T08:43:52.758631Z",
     "iopub.status.busy": "2025-03-20T08:43:52.758194Z",
     "iopub.status.idle": "2025-03-20T08:43:52.833153Z",
     "shell.execute_reply": "2025-03-20T08:43:52.831936Z"
    },
    "papermill": {
     "duration": 0.081787,
     "end_time": "2025-03-20T08:43:52.835081",
     "exception": false,
     "start_time": "2025-03-20T08:43:52.753294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Data Shape: (5000, 14)\n",
      "Duplicate Rows: 13\n",
      "Shape after dropping duplicates: (4987, 12)\n",
      "Num of features to standardize: 11\n"
     ]
    }
   ],
   "source": [
    "df_pre_processed  = preprocess_data(file_path=file_path, \n",
    "                drop_cols=drop_cols, \n",
    "                target_col=target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ad8f568",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T08:43:52.844831Z",
     "iopub.status.busy": "2025-03-20T08:43:52.844478Z",
     "iopub.status.idle": "2025-03-20T08:43:52.851127Z",
     "shell.execute_reply": "2025-03-20T08:43:52.849557Z"
    },
    "papermill": {
     "duration": 0.013638,
     "end_time": "2025-03-20T08:43:52.853055",
     "exception": false,
     "start_time": "2025-03-20T08:43:52.839417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIFT cols: (4987, 7)\n"
     ]
    }
   ],
   "source": [
    "df_gift = df_pre_processed[gift_cols_target]\n",
    "print(f'GIFT cols: {df_gift.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0993250",
   "metadata": {
    "papermill": {
     "duration": 0.003908,
     "end_time": "2025-03-20T08:43:52.861351",
     "exception": false,
     "start_time": "2025-03-20T08:43:52.857443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e529832f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T08:43:52.871038Z",
     "iopub.status.busy": "2025-03-20T08:43:52.870601Z",
     "iopub.status.idle": "2025-03-20T08:43:52.877269Z",
     "shell.execute_reply": "2025-03-20T08:43:52.875977Z"
    },
    "papermill": {
     "duration": 0.013562,
     "end_time": "2025-03-20T08:43:52.879063",
     "exception": false,
     "start_time": "2025-03-20T08:43:52.865501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main_function(df, target_col, classifiers): \n",
    "    trained_models = {}\n",
    "    print(f' {\"*\" * 20} Train Test Split {\"*\" * 20}')\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = split_data(df=df, target_col=target_col)\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for name, classifier in classifiers.items():\n",
    "        classifier.fit(X_train, y_train)\n",
    "        trained_models[name]  = classifier\n",
    "        print(f\"\\n{classifier.__class__.__name__} Trained\")\n",
    "    \n",
    "        print(f' {\"*\" * 20} Validation Set {\"*\" * 20}')\n",
    "        evaluate_model(model = classifier, X_true=X_val, y_true=y_val)\n",
    "        print(f' {\"*\" * 20} Test Set {\"*\" * 20}')\n",
    "        evaluate_model(model = classifier, X_true = X_test, y_true=y_test)\n",
    "        print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0146fc30",
   "metadata": {
    "papermill": {
     "duration": 0.003889,
     "end_time": "2025-03-20T08:43:52.887324",
     "exception": false,
     "start_time": "2025-03-20T08:43:52.883435",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **ML models withOUT feature selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4e34a66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T08:43:52.897021Z",
     "iopub.status.busy": "2025-03-20T08:43:52.896628Z",
     "iopub.status.idle": "2025-03-20T08:43:54.741437Z",
     "shell.execute_reply": "2025-03-20T08:43:54.739672Z"
    },
    "papermill": {
     "duration": 1.851782,
     "end_time": "2025-03-20T08:43:54.743277",
     "exception": false,
     "start_time": "2025-03-20T08:43:52.891495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ******************** Train Test Split ********************\n",
      "Train Shape: (3590, 11), Validation Shape: (898, 11), Test Shape: (499, 11)\n",
      "\n",
      "Target Distribution in Train Set:\n",
      "Personal Loan\n",
      "0    0.903621\n",
      "1    0.096379\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Target Distribution in Validation Set:\n",
      "Personal Loan\n",
      "0    0.904232\n",
      "1    0.095768\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Target Distribution in Test Set:\n",
      "Personal Loan\n",
      "0    0.903808\n",
      "1    0.096192\n",
      "Name: proportion, dtype: float64\n",
      "============================================================\n",
      "\n",
      "SVC Trained\n",
      " ******************** Validation Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[811   1]\n",
      " [ 21  65]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9755\n",
      "Precision: 0.9848\n",
      "Recall: 0.7558\n",
      "F1-Score: 0.8553\n",
      "Specificity: 0.9988\n",
      " ******************** Test Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[449   2]\n",
      " [ 16  32]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9639\n",
      "Precision: 0.9412\n",
      "Recall: 0.6667\n",
      "F1-Score: 0.7805\n",
      "Specificity: 0.9956\n",
      "============================================================\n",
      "\n",
      "LogisticRegression Trained\n",
      " ******************** Validation Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[806   6]\n",
      " [ 31  55]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9588\n",
      "Precision: 0.9016\n",
      "Recall: 0.6395\n",
      "F1-Score: 0.7483\n",
      "Specificity: 0.9926\n",
      " ******************** Test Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[444   7]\n",
      " [ 26  22]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9339\n",
      "Precision: 0.7586\n",
      "Recall: 0.4583\n",
      "F1-Score: 0.5714\n",
      "Specificity: 0.9845\n",
      "============================================================\n",
      "\n",
      "RandomForestClassifier Trained\n",
      " ******************** Validation Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[812   0]\n",
      " [  9  77]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9900\n",
      "Precision: 1.0000\n",
      "Recall: 0.8953\n",
      "F1-Score: 0.9448\n",
      "Specificity: 1.0000\n",
      " ******************** Test Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[451   0]\n",
      " [  7  41]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9860\n",
      "Precision: 1.0000\n",
      "Recall: 0.8542\n",
      "F1-Score: 0.9213\n",
      "Specificity: 1.0000\n",
      "============================================================\n",
      "\n",
      "GradientBoostingClassifier Trained\n",
      " ******************** Validation Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[812   0]\n",
      " [  9  77]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9900\n",
      "Precision: 1.0000\n",
      "Recall: 0.8953\n",
      "F1-Score: 0.9448\n",
      "Specificity: 1.0000\n",
      " ******************** Test Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[451   0]\n",
      " [  9  39]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9820\n",
      "Precision: 1.0000\n",
      "Recall: 0.8125\n",
      "F1-Score: 0.8966\n",
      "Specificity: 1.0000\n",
      "============================================================\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 346, number of negative: 3244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003990 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 619\n",
      "[LightGBM] [Info] Number of data points in the train set: 3590, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.096379 -> initscore=-2.238124\n",
      "[LightGBM] [Info] Start training from score -2.238124\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LGBMClassifier Trained\n",
      " ******************** Validation Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[811   1]\n",
      " [  8  78]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9900\n",
      "Precision: 0.9873\n",
      "Recall: 0.9070\n",
      "F1-Score: 0.9455\n",
      "Specificity: 0.9988\n",
      " ******************** Test Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[450   1]\n",
      " [  8  40]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9820\n",
      "Precision: 0.9756\n",
      "Recall: 0.8333\n",
      "F1-Score: 0.8989\n",
      "Specificity: 0.9978\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "main_function(df=df_pre_processed, target_col = target_col, classifiers=classifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0dd8db",
   "metadata": {
    "papermill": {
     "duration": 0.004206,
     "end_time": "2025-03-20T08:43:54.752378",
     "exception": false,
     "start_time": "2025-03-20T08:43:54.748172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **ML models with feature selection -- GIFT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "778c4832",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-20T08:43:54.762966Z",
     "iopub.status.busy": "2025-03-20T08:43:54.762566Z",
     "iopub.status.idle": "2025-03-20T08:43:56.140429Z",
     "shell.execute_reply": "2025-03-20T08:43:56.138850Z"
    },
    "papermill": {
     "duration": 1.385274,
     "end_time": "2025-03-20T08:43:56.142343",
     "exception": false,
     "start_time": "2025-03-20T08:43:54.757069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ******************** Train Test Split ********************\n",
      "Train Shape: (3590, 6), Validation Shape: (898, 6), Test Shape: (499, 6)\n",
      "\n",
      "Target Distribution in Train Set:\n",
      "Personal Loan\n",
      "0    0.903621\n",
      "1    0.096379\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Target Distribution in Validation Set:\n",
      "Personal Loan\n",
      "0    0.904232\n",
      "1    0.095768\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Target Distribution in Test Set:\n",
      "Personal Loan\n",
      "0    0.903808\n",
      "1    0.096192\n",
      "Name: proportion, dtype: float64\n",
      "============================================================\n",
      "\n",
      "SVC Trained\n",
      " ******************** Validation Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[812   0]\n",
      " [ 14  72]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9844\n",
      "Precision: 1.0000\n",
      "Recall: 0.8372\n",
      "F1-Score: 0.9114\n",
      "Specificity: 1.0000\n",
      " ******************** Test Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[449   2]\n",
      " [ 15  33]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9659\n",
      "Precision: 0.9429\n",
      "Recall: 0.6875\n",
      "F1-Score: 0.7952\n",
      "Specificity: 0.9956\n",
      "============================================================\n",
      "\n",
      "LogisticRegression Trained\n",
      " ******************** Validation Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[803   9]\n",
      " [ 37  49]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9488\n",
      "Precision: 0.8448\n",
      "Recall: 0.5698\n",
      "F1-Score: 0.6806\n",
      "Specificity: 0.9889\n",
      " ******************** Test Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[442   9]\n",
      " [ 26  22]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9299\n",
      "Precision: 0.7097\n",
      "Recall: 0.4583\n",
      "F1-Score: 0.5570\n",
      "Specificity: 0.9800\n",
      "============================================================\n",
      "\n",
      "RandomForestClassifier Trained\n",
      " ******************** Validation Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[812   0]\n",
      " [  9  77]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9900\n",
      "Precision: 1.0000\n",
      "Recall: 0.8953\n",
      "F1-Score: 0.9448\n",
      "Specificity: 1.0000\n",
      " ******************** Test Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[450   1]\n",
      " [  8  40]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9820\n",
      "Precision: 0.9756\n",
      "Recall: 0.8333\n",
      "F1-Score: 0.8989\n",
      "Specificity: 0.9978\n",
      "============================================================\n",
      "\n",
      "GradientBoostingClassifier Trained\n",
      " ******************** Validation Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[811   1]\n",
      " [  9  77]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9889\n",
      "Precision: 0.9872\n",
      "Recall: 0.8953\n",
      "F1-Score: 0.9390\n",
      "Specificity: 0.9988\n",
      " ******************** Test Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[451   0]\n",
      " [  8  40]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9840\n",
      "Precision: 1.0000\n",
      "Recall: 0.8333\n",
      "F1-Score: 0.9091\n",
      "Specificity: 1.0000\n",
      "============================================================\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 346, number of negative: 3244\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 516\n",
      "[LightGBM] [Info] Number of data points in the train set: 3590, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.096379 -> initscore=-2.238124\n",
      "[LightGBM] [Info] Start training from score -2.238124\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "LGBMClassifier Trained\n",
      " ******************** Validation Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[807   5]\n",
      " [  9  77]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9844\n",
      "Precision: 0.9390\n",
      "Recall: 0.8953\n",
      "F1-Score: 0.9167\n",
      "Specificity: 0.9938\n",
      " ******************** Test Set ********************\n",
      "\n",
      "Confusion Matrix:\n",
      "[[451   0]\n",
      " [  8  40]]\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.9840\n",
      "Precision: 1.0000\n",
      "Recall: 0.8333\n",
      "F1-Score: 0.9091\n",
      "Specificity: 1.0000\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "main_function(df=df_gift, target_col = target_col, classifiers=classifiers_gift)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 608073,
     "sourceId": 1089480,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.159829,
   "end_time": "2025-03-20T08:43:57.171049",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-20T08:43:43.011220",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
